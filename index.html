<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
    <meta name=viewport content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
        /* Color scheme stolen from Sergey Karayev */
        
        a {
            color: #1772d0;
            text-decoration: none;
        }
        
        a:focus,
        a:hover {
            color: #f09228;
            text-decoration: none;
        }
        
        body,
        td,
        th,
        tr,
        p,
        a {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 15px
        }
        
        strong {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 15px;
        }
        
        heading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 24px;
        }
        
        papertitle {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 15px;
            font-weight: 700
        }
        
        name {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 32px;
        }
        
        .one {
            width: 160px;
            height: 160px;
            position: relative;
        }
        
        .two {
            width: 160px;
            height: 160px;
            position: absolute;
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }
        
        .fade {
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }
        
        span.highlight {
            background-color: #ffffd0;
        }
    </style>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <!-- https://fontawesome.com/cheatsheet -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="icon" type="image/png" href="images/csail_logo.png">
    <title>Tao Chen</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>
<script>
    function toggleblock(blockId) {
        var block = document.getElementById(blockId);
        if (block.style.display == 'none') {
            block.style.display = 'block';
        } else {
            block.style.display = 'none';
        }
    }

    function hideblock(blockId) {
        var block = document.getElementById(blockId);
        block.style.display = 'none';
    }
</script>
<!-- Place this tag in your head or just before your close body tag. -->
<script async defer src="https://buttons.github.io/buttons.js"></script>

<body>
    <table width="1000" border="0" align="center" cellspacing="0" cellpadding="0">
        <tr>
            <td>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td width="67%" valign="middle">
                            <p align="center">
                                <name>Tao Chen (陈涛) </name>
                            </p>
                            <p>
                                I am a Ph.D. student in EECS at <a href="https://www.csail.mit.edu/" target="_blank">MIT CSAIL</a>, advised by Prof. <a href="http://people.csail.mit.edu/pulkitag/" target="_blank">Pulkit Agrawal</a>. My research interests
                                revolve around the intersection of robot learning (dexterous manipulation, locomotion, navigation).
                            </p>
                            <p>
                                I received my master's degree from the <a href="http://ri.cmu.edu/" target="_blank">Robotics Institute, Carnegie Mellon University (CMU RI)</a> in May 2019, advised by Prof. <a href="http://www.cs.cmu.edu/~abhinavg/" target="_blank">Abhinav Gupta</a>.
                            </p>
                            <p>
                                Prior to this, I was a research engineer in <i><b>Shanghai LX Robotics</b></i>, where I conducted research on <i>object detection, image segmentation, deep reinforcement learning in robotics, SLAM, etc</i>.
                            </p>
                            <p>
                                I earned my bachelor's degree from <a href="http://www.sjtu.edu.cn/" target="_blank">Shanghai Jiao Tong University (SJTU)</a> in June 2016, majoring in <b>mechanical engineering and automation</b>. I was also an exchange
                                student (<a href="https://opp.purdue.edu/programs/geare/" target="_blank">GEARE</a> program) at <a href="https://engineering.purdue.edu/ME" target="_blank">School of Mechanical Engineering, Purdue University</a>.
                            </p>
                            <p align=center>
                                <a href="mailto:taochen@mit.edu">Email</a> &nbsp/&nbsp
                                <a href="files/taochen_cv.pdf" target="_blank">CV</a> &nbsp/&nbsp
                                <a href="https://scholar.google.com/citations?user=gdUv1PIAAAAJ&hl=en&oi=sra" target="_blank">Google Scholar</a> &nbsp/&nbsp
                                <a href="https://github.com/taochenshh" target="_blank">GitHub</a>&nbsp/&nbsp
                                <a href="https://linkedin.com/in/taochenshh" target="_blank">LinkedIn</a>&nbsp/&nbsp
                                <a href="https://twitter.com/taochenshh" target="_blank">Twitter</a>
                            </p>
                        </td>
                        <td width="33%">
                            <img src="images/my_photo.jpg" style="display:block;" width="100%">
                        </td>
                    </tr>
                </table>
                <table>
                    <tr>
                        <td valign="middle">
                            <p>
                                <heading>News</heading>
                                <ul>
                                    <li>I am organizing the <a href="https://ei.csail.mit.edu/csl.html">Computational Sensorimotor Learning Seminar</a>. Recordings are available <a href="https://www.youtube.com/playlist?list=PLwNwxAG-kBxNBgIXogC6AShE5wzeXgoa6">here</a>.</li>
                                    <li>Our paper on in-hand object reorientation wins the
                                        <font color="red">Best Paper Award</font> at CoRL 2021.</li>
                                    <!-- <li>Our paper on in-hand object reorientation is accepted to CoRL 2021 (<strong>oral</strong>).</li> -->
                                    <!-- <li>Our paper on dynamic vision-aware locomotion is accepted to CoRL 2021.</li>
                                    <li>Our paper on end-to-end differentiable simulator for robot design and control co-optimization is accepted to RSS 2021. </li>
                                    <li>Our paper on data-efficient policy learning for microrobots with complex dynamics is accepted to ICRA 2021.</li>
                                    <li>New course: <a href="https://pulkitag.github.io/6.884/" target="_blank">Computational Sensorimotor Learning</a> is online, checkout the lecture videos on <a href="https://youtube.com/playlist?list=PLwNwxAG-kBxPMTIs2fKWSsf7HqL2TcC78"
                                            target="_blank">YouTube</a>.</li>
                                    <li>A crash course on deep learning and robotics: <a href="https://pulkitag.github.io/rlbootcamp-iap/">Deep Learning for Control</a>. The lecture videos are available online.</li>
                                    <li>Our python-oriented robot learning library, <a href="https://github.com/Improbable-AI/airobot" target="_blank">AIRobot</a>, is open-sourced!</li>
                                    <li>Our open-source robotics research platform, <a href="https://www.pyrobot.org/" target="_blank">PyRobot</a>, is now online!</li> -->
                                </ul>
                                <br>
                            </p>
                        </td>
                    </tr>
                </table>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td>
                            <heading>Research</heading>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <a href="https://openreview.net/forum?id=7uSBJDoP7tY" target="_blank">
                                <!-- <img src="images/hand_reori/hand_reori1.gif" alt="sym" width="100%" style="border-radius:5px"> -->
                                <!-- <br>  -->
                                <img src="images/hand_reori/hand_reori2.gif" alt="sym" width="100%" style="border-radius:5px">
                            </a>
                        </td>
                        <td valign="top" style="padding:20px;width:75%;vertical-align:middle">
                            <papertitle>A System for General In-Hand Object Re-Orientation
                            </papertitle>
                            <br>
                            <strong>Tao Chen</strong>, <a href="http://people.csail.mit.edu/jiex" target="_blank">Jie Xu</a>,
                            <a href="http://people.csail.mit.edu/pulkitag/" target="_blank">Pulkit Agrawal</a>
                            <br>
                            <em>Conference on Robot Learning (<strong>CoRL</strong>)</em>, 2021 <strong>(<font color="red">Best Paper Award</font>), (<font color="red">Oral</font>, acceptance rate: 6.5%)</strong>
                            <br>
                            <a href="https://openreview.net/forum?id=7uSBJDoP7tY" target="_blank">paper</a> /
                            <a href="https://arxiv.org/abs/2111.03043" target="_blank">arXiv</a> /
                            <a href="javascript:toggleblock('chen2021system_bib')">bibtex</a> /
                            <a href="https://taochenshh.github.io/projects/in-hand-reorientation" target="_blank">project page</a> /
                            <a href="https://youtu.be/r7neFpA20ck" target="_blank">oral talk</a>
                            <bibtext xml:space="preserve" id="chen2021system_bib">
                                @article{chen2021system,<br /> title={A System for General In-Hand Object Re-Orientation},<br /> author={Chen, Tao and Xu, Jie and Agrawal, Pulkit},<br /> journal={Conference on Robot Learning},<br /> year={2021}
                                <br /> }
                            </bibtext>
                            <script language="JavaScript">
                                hideblock('chen2021system_bib');
                            </script>
                            <br><br> Press coverage:
                            <a href="https://news.mit.edu/2021/dexterous-robotic-hands-manipulate-thousands-objects-1112" target="_blank">MIT News</a>,
                            <a href="https://www.csail.mit.edu/news/dexterous-robotic-hands-manipulate-thousands-objects-ease" target="_blank">MIT CSAIL News</a>,
                            <a href="https://www.azorobotics.com/Article.aspx?ArticleID=426" target="_blank">AZO Robotics</a>,
                            <a href="https://aihub.org/2021/11/24/interview-with-tao-chen-jie-xu-and-pulkit-agrawal-corl-2021-best-paper-award-winners/" target="_blank">AIHub</a>,
                            <a href="https://mp.weixin.qq.com/s/hjJ4R_AifvRaZJ9gH6_AbA" target="_blank">AI科技评论</a>,
                            <a href="https://techxplore.com/news/2021-11-dexterous-robotic-thousands-ease.html" target="_blank">Tech Xplore</a>,
                            <a href="https://cacm.acm.org/news/256757-dexterous-robotic-hands-manipulate-objects-with-ease/fulltext" target="_blank">Communications of the ACM</a>,
                            <a href="https://www.inceptivemind.com/new-ai-system-allows-robots-manipulate-thousands-objects/21936/" target="_blank">Inceptive Mind</a>,
                            <a href="https://spectrum.ieee.org/video-friday-fridgebot" target="_blank">IEEE Spectrum</a>,
                            <a href="https://thehackposts.com/dexterous-robotic-hands-manipulate-thousands-of-objects-with-ease/" target="_blank">The Hack Posts</a>,
                            <a href="https://tectales.com/bionics-robotics/robotic-hands-manipulate-objects-with-ease.html" target="_blank">Tectales</a>,
                            <a href="https://www.therobotreport.com/mit-teaches-robotic-hands-to-reorient-2000-objects-in-one-hand/" target="_blank">The Robot Report</a>
                            <p></p>
                            <p>A system for general in-hand object reorientation.
                            </p>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <a href="https://taochenshh.github.io/" target="_blank">
                                <img src="images/cheetah-spin-2022.png" alt="sym" width="100%" style="border-radius:5px">
                            </a>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <papertitle>Rapid Locomotion via Reinforcement Learning
                            </papertitle>
                            <br>
                            <a href="http://people.csail.mit.edu/gmargo/" target="_blank">Gabriel Margolis</a>,
                            <a href="https://www.episodeyang.com/" target="_blank">Ge Yang</a>,
                            <a href="https://kartikpaigwar.github.io/" target="_blank">Kartik Paigwar</a>,
                            <strong>Tao Chen</strong>,
                            <a href="http://people.csail.mit.edu/pulkitag/" target="_blank">Pulkit Agrawal</a>
                            <br>
                            <em>Robotics: Science and Systems (<strong>RSS</strong>)</em>, 2022
                            <br>
                            <a href="https://arxiv.org/pdf/2205.02824.pdf" target="_blank">paper</a> /
                            <a href="https://sites.google.com/view/model-free-speed/" target="_blank">project page</a> /
                            <a href="javascript:toggleblock('margolis2022rapid_bib')">bibtex</a> /
                            <a href="https://youtu.be/-BqNl3AtPVw" target="_blank">video</a> /
                            <bibtext xml:space="preserve" id="margolis2022rapid_bib">
                                @article{margolis2022rapid, <br />
                                    title={Rapid Locomotion via Reinforcement Learning}, <br />
                                    author={Margolis, Gabriel B and Yang, Ge and Paigwar, Kartik and Chen, Tao and Agrawal, Pulkit}, <br />
                                    journal={Robotics: Science and Systems}, <br />
                                    year={2022} <br />
                                }
                            </bibtext>
                            <script language="JavaScript">
                                hideblock('margolis2022rapid_bib');
                            </script>
                            <br><br> Press coverage:
                            <a href="https://www.wired.com/story/this-cheetah-robot-taught-itself-how-to-sprint-in-a-weird-way/">Wired</a>,
                            <a href="https://www.popsci.com/technology/machine-learning-robot-runs-its-fastest/"> Popular Science</a>,
                            <a href="https://techcrunch.com/2022/03/17/to-servi-man/"> TechCrunch</a>,
                            <a href="https://www.bbc.com/news/av/technology-60795221">BBC </a>,
                            <a href="https://news.mit.edu/2022/3-questions-how-mit-mini-cheetah-learns-run-fast-0317"> MIT News </a>
                            <p></p>
                            <p>High-speed running and spinning on diverse terrains with a RL based controller.
                            </p>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <a href="https://taochenshh.github.io/" target="_blank">
                                <img src="images/ter/ter_teaser.png" alt="sym" width="100%" style="border-radius:5px">
                            </a>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <papertitle>Topological Experience Replay
                            </papertitle>
                            <br>
                            <a href="https://williamd4112.github.io/" target="_blank">Zhang-Wei Hong</a>,
                            <strong>Tao Chen</strong>,
                            <a href="https://yenchenlin.me/" target="_blank">Yen-Chen Lin</a>,
                            <a href="https://people.aalto.fi/joni.pajarinen" target="_blank">Joni Pajarinen</a>,
                            <a href="http://people.csail.mit.edu/pulkitag/" target="_blank">Pulkit Agrawal</a>
                            <br>
                            <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2022
                            <br>
                            <a href="https://openreview.net/forum?id=OXRZeMmOI7a" target="_blank">paper</a> /
                            <a href="javascript:toggleblock('hong2021ter_bib')">bibtex</a> /
                            <a href="https://www.youtube.com/watch?v=IWRxZfJsV2Q" target="_blank">video</a> /
                            <bibtext xml:space="preserve" id="hong2021ter_bib">
                                @inproceedings{ <br />
                                    hong2022topological, <br />
                                    title={Topological Experience Replay}, <br />
                                    author={Hong, Zhang-Wei and Chen, Tao and Lin, Yen-Chen and Pajarinen, Joni and Agrawal, Pulkit}, <br />
                                    booktitle={In Proceedings of The Tenth International Conference on Learning Representations }, <br />
                                    year={2022}, <br />
                                    url={https://openreview.net/forum?id=OXRZeMmOI7a}, <br />
                                }
                            </bibtext>
                            <script language="JavaScript">
                                hideblock('hong2021ter_bib');
                            </script>
                            <p></p>
                            <p>A fast Q-learning method by building a topological graph in the replay buffer.
                            </p>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <a href="https://openreview.net/pdf?id=R4E8wTUtxdl" target="_blank">
                                <img src="images/cheetah/cheetah-jump.gif" alt="sym" width="100%" style="border-radius:5px">
                            </a>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <papertitle>Learning to Jump from Pixels
                            </papertitle>
                            <br>
                            <a href="http://people.csail.mit.edu/gmargo/" target="_blank">Gabriel Margolis</a>,
                            <strong>Tao Chen</strong>,
                            <a href="https://kartikpaigwar.github.io/" target="_blank">Kartik Paigwar</a>,
                            <a href="https://xiangfu.co/" target="_blank">Xiang Fu</a>,
                            <a href="https://dhkim0821.github.io/" target="_blank">Donghyun Kim</a>,
                            <a href="http://meche.mit.edu/people/faculty/sangbae@mit.edu" target="_blank">Sangbae Kim</a>,
                            <a href="http://people.csail.mit.edu/pulkitag/" target="_blank">Pulkit Agrawal</a>
                            <br>
                            <em>Conference on Robot Learning (<strong>CoRL</strong>)</em>, 2021
                            <br>
                            <a href="https://openreview.net/pdf?id=R4E8wTUtxdl" target="_blank">paper</a> /
                            <a href="data/margolis2021jumping.bib">bibtex</a> /
                            <a href="https://sites.google.com/view/jumpingfrompixels" target="_blank">project page</a>
                            <bibtext xml:space="preserve" id="margolis2021jumping_bib">
                                @article{margolis2021jumping, <br /> title={Learning to Jump from Pixels}, <br /> author={Margolis, Gabriel and Chen, Tao and Paigwar, Kartik and Fu, Xiang and Kim, Donghyun and Kim, Sangbae and Agrawal, Pulkit}, <br />                                journal={Conference on Robot Learning}, <br /> year={2021} <br /> }
                            </bibtext>
                            <script language="JavaScript">
                                hideblock('margolis2021jumping_bib');
                            </script>
                            <br><br>
                            <strong>Press Coverage:</strong> <a href="https://news.mit.edu/2021/one-giant-leap-mini-cheetah-1020" target="_blank">MIT News</a>,
                            <a href="https://www.azorobotics.com/article.aspx?ArticleID=413" target="_blank">AZO Robotics</a>,
                            <a href="https://www.therobotreport.com/mit-control-system-improves-agility-of-cheetah-quadruped/" target="_blank">The Robot Report</a>

                            <p></p>
                            <p> A hierarchical control framework for dynamic vision-aware locomotion. </p>
                        </td>
                    </tr>
                </table>


                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <a href="https://arxiv.org/pdf/2104.00631.pdf" target="_blank">
                                <img src="images/diff_sim.jpg" alt="sym" width="100%" style="border-radius:5px">
                            </a>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <papertitle>An End-to-End Differentiable Framework for Contact-Aware Robot Design
                            </papertitle>
                            <br>
                            <a href="http://people.csail.mit.edu/jiex" target="_blank">Jie Xu</a>,
                            <strong>Tao Chen</strong>, <a href="https://lara-z.github.io/" target="_blank">Lara Zlokapa</a>,
                            <a href="https://scholar.google.co.uk/citations?user=NQMazscAAAAJ&hl=en" target="_blank">Michael Foshey</a>,
                            <a href="https://cdfg.mit.edu/wojciech" target="_blank">Wojciech Matusik</a>,
                            <a href="https://people.engr.tamu.edu/sueda/index.html" target="_blank">Shinjiro Sueda</a>,
                            <a href="http://people.csail.mit.edu/pulkitag/" target="_blank">Pulkit Agrawal</a>
                            <br>
                            <em>Robotics: Science and Systems (<strong>RSS</strong>) </em>, 2021

                            <br>
                            <a href="https://people.csail.mit.edu/jiex/papers/DiffHand/paper.pdf" target="_blank">paper</a> /
                            <a href="https://arxiv.org/abs/2107.07501" target="_blank">arXiv</a> /
                            <a href="javascript:toggleblock('xu2021diffsim_bib')">bibtex</a> /
                            <a href="http://diffhand.csail.mit.edu/" target="_blank">project page</a> /
                            <a href="https://github.com/eanswer/DiffHand" target="_blank">code</a> /
                            <a href="https://people.csail.mit.edu/jiex/papers/DiffHand/video.mp4" target="_blank">video</a> /
                            <a href="https://www.youtube.com/watch?v=KUpgXu5hQYM" target="_blank">talk</a>
                            <bibtext xml:space="preserve" id="xu2021diffsim_bib">
                                @article{xu2021diffsim,<br /> title={An End-to-End Differentiable Framework for Contact-Aware Robot Design},<br /> author={Xu, Jie and Chen, Tao and Zlokapa, Lara and Matusik, Wojciech and Sueda, Shinjiro and Agrawal, Pulkit},<br
                                /> journal={Robotics: Science and Systems},<br /> year={2021}
                                <br /> }
                            </bibtext>
                            <script language="JavaScript">
                                hideblock('xu2021diffsim_bib');
                            </script>
                            <br><br>
                            <strong>Press Coverage:</strong> <a href="https://news.mit.edu/2021/contact-aware-robot-design-0719" target="_blank">MIT News</a>, <a href="https://www.techexplorist.com/representing-robotic-manipulator-using-a-novel-method/40098/"
                                target="_blank">Tectales</a>
                            <p></p>
                            <p> Computational method for design task-specific robotic hands.
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <a href="https://arxiv.org/pdf/2104.00631.pdf" target="_blank">
                                <img src="images/hamr/hamr_rml_logo.png" alt="sym" width="100%" style="border-radius:5px">
                                <!-- <br> -->
                                <!-- <img src="images/hamr/hamr.gif" width="100%"> -->
                            </a>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <papertitle>Residual Model Learning for Microrobot Control
                            </papertitle>
                            <br>
                            <a href="https://joshuagruenstein.github.io/" target="_blank">Joshua Gruenstein</a>,
                            <strong>Tao Chen</strong>,
                            <a href="https://neeld.github.io/" target="_blank">Neel Doshi</a>,
                            <a href="http://people.csail.mit.edu/pulkitag/" target="_blank">Pulkit Agrawal</a>
                            <br>
                            <em>IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>) </em>, 2021
                            <br>
                            <a href="https://arxiv.org/pdf/2104.00631.pdf" target="_blank">paper</a> /
                            <a href="javascript:toggleblock('gruenstein2021residual_bib')">bibtex</a> /
                            <a href="https://sites.google.com/view/hamr-icra-2021" target="_blank">project page</a> /
                            <a href="https://youtu.be/rwsz5f2Yp8g" target="_blank">video</a>
                            <bibtext xml:space="preserve" id="gruenstein2021residual_bib">
                                @article{gruenstein2021residual,<br /> title={Residual Model Learning for Microrobot Control},<br /> author={Gruenstein, Joshua and Chen, Tao and Doshi, Neel and Agrawal, Pulkit},<br /> journal={International Conference
                                on Robotics and Automation},<br /> year={2021}
                                <br /> }
                            </bibtext>
                            <script language="JavaScript">
                                hideblock('gruenstein2021residual_bib');
                            </script>
                            <p></p>
                            <p>A data-efficient learning method for controlling microrobots with complex dynamics.</p>
                        </td>
                    </tr>



                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <a href="https://taochenshh.github.io/" target="_blank">
                                <img src="images/regular_exp/craft_env.png" alt="sym" width="100%" style="border-radius:5px">
                            </a>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <papertitle>Language Inference for Reward Learning</papertitle>
                            <br> Xiang Fu,
                            <strong>Tao Chen</strong>,
                            <a href="http://people.csail.mit.edu/pulkitag/" target="_blank">Pulkit Agrawal</a>,
                            <a href="http://people.csail.mit.edu/tommi/" target="_blank">Tommi S. Jaakkola</a>
                            <br>
                            <em><a href="https://sites.google.com/view/biologicalandartificialrl" target="_blank">NeurIPS Biological and Artifical RL workshop</a>, 2020</em>
                            <br>
                            <a href="files/regular_exp_paper.pdf" target="_blank">paper</a> /
                            <a href="javascript:toggleblock('fu2020language_bib')">bibtex</a>
                            <bibtext xml:space="preserve" id="fu2020language_bib">
                                @inproceedings{fu2020language,<br /> author = {Xiang Fu and Tao Chen and Pulkit Agrawal and Tommi Jaakkola},<br /> title = {Language Inference for Reward Learning},<br /> booktitle = {Advances in Neural Information Processing
                                Systems Workshop (Biological and Artificial Reinforcement Learning)},<br /> year = {2020}<br /> }
                                <br />
                            </bibtext>
                            <script language="JavaScript">
                                hideblock('fu2020language_bib');
                            </script>
                            <p></p>
                            <p> Reward learning by using formal language (regular expression) to capture the reward structure.</p>
                        </td>
                    </tr>


                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <a href="https://sites.google.com/view/learn-from-failures" target="_blank">
                                <!--                                    <img src="images/snail_memory/snail_memory_net_arch.png" alt="sym" width="100%" style="border-radius:5px">-->
                                <img src="images/snail_memory/ur.gif" alt="sym" width="100%" style="border-radius:5px">
                                <!--                                  <img src="images/snail_memory/2dgridworld.gif" alt="sym" width="100%" style="border-radius:5px">-->
                                <!--                                    <img src="images/snail_memory/3dminiworld.gif" alt="sym" width="100%" style="border-radius:5px">-->
                            </a>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <papertitle>Learning to Learn from Failures using Replay</papertitle>
                            <br>
                            <strong>Tao Chen</strong>,
                            <a href="http://people.csail.mit.edu/pulkitag/" target="_blank">Pulkit Agrawal</a>
                            <br>
                            <em><a href="https://biases-invariances-generalization.github.io/index.html" target="_blank">ICML BIG workshop</a>, 2020 </em>
                            <br>
                            <a href="https://biases-invariances-generalization.github.io/pdf/big_18.pdf" target="_blank">paper(workshop version)</a> /
                            <a href="javascript:toggleblock('chen2020memory_bib')">bibtex</a> /
                            <a href="https://sites.google.com/view/learn-from-failures" target="_blank">project page</a>
                            <bibtext xml:space="preserve" id="chen2020memory_bib">
                                @inproceedings{chen2020memory,<br /> author = {Tao Chen and Pulkit Agrawal},<br /> title = {Learning to Learn from Failures using Replay},<br /> booktitle = {International Conference on Machine Learning Workshop (Inductive
                                Biases, Invariances and Generalization in RL)},<br /> year = {2020}<br /> }
                                <br />
                            </bibtext>
                            <script language="JavaScript">
                                hideblock('chen2020memory_bib');
                            </script>
                            <p></p>
                            <p> Remembering failures aids faster learning by preventing the agent to oscillate between mistakes.</p>
                        </td>
                    </tr>



                    <tr>
                        <td width="25%" align="center">
                            <a href="https://arxiv.org/abs/1906.08236" target="_blank"><img src="images/pyrobot_logo.svg" width="100%" /></a>
                        </td>
                        <td width="75%" valign="top">
                            <p>
                                <papertitle>PyRobot: An Open-source Robotics Framework for Research and Benchmarking</papertitle>
                                <br>
                                <a href="http://www.adithyamurali.com" target="_blank">Adithya Murali*</a>, <strong>Tao Chen*</strong>, <a href="https://www.ri.cmu.edu/ri-people/kalyan-vasudev-alwala/" target="_blank">Kalyan Vasudev Alwala*</a>, <a href="http://www.cs.cmu.edu/~dgandhi/"
                                    target="_blank">Dhiraj Gandhi*</a>, <a href="http://www.cs.cmu.edu/~lerrelp/" target="_blank">Lerrel Pinto</a>, <a href="http://saurabhg.web.illinois.edu/" target="_blank">Saurabh Gupta</a>, <a href="http://www.cs.cmu.edu/~abhinavg/"
                                    target="_blank">Abhinav Gupta</a> [* Equal contribution]

                                <br>
                                <a href="https://arxiv.org/abs/1906.08236" target="_blank">paper</a> / <a href="javascript:toggleblock('pyrobot2019_bib')">bibtex</a> / <a href="https://www.pyrobot.org/" target="_blank">project page</a> / <a href="https://github.com/facebookresearch/pyrobot"
                                    target="_blank">code</a> <a class="github-button" href="https://github.com/facebookresearch/pyrobot" data-icon="octicon-star" data-show-count="true" aria-label="Star facebookresearch/pyrobot on GitHub" target="_blank">GitHub Star</a>                                / <a href="https://ai.facebook.com/blog/open-sourcing-pyrobot-to-accelerate-ai-robotics-research/" target="_blank">facebook AI blog</a>
                                <bibtext xml:space="preserve" id="pyrobot2019_bib">
                                    @article{pyrobot2019,<br /> author = {Adithyavairavan Murali* and Tao Chen* and Kalyan Vasudev Alwala* and Dhiraj Gandhi* and Lerrel Pinto and Saurabh Gupta and Abhinav Gupta},<br /> title = {{PyRobot}: An Open-source
                                    Robotics Framework for Research and Benchmarking},<br /> journal = {CoRR},<br /> volume = {abs/1906.08236},<br /> year = {2019},<br /> url = {https://arxiv.org/abs/1906.08236},<br /> archivePrefix = {arXiv},<br /> eprint
                                    = {1906.08236}<br /> }
                                    <br />
                                </bibtext>
                                <script language="JavaScript">
                                    hideblock('pyrobot2019_bib');
                                </script>
                                <br><br>
                                <strong>Press Coverage:</strong> <a href="https://www.wired.com/story/facebook-unleashes-software-to-make-programming-robots-easy/" target="_blank">WIRED</a>, <a href="https://venturebeat.com/2019/06/20/facebook-launches-robotics-framework-pyrobot/"
                                    target="_blank">VentureBeat</a>, <a href="https://www.therobotreport.com/facebook-pyrobot-open-source-speed-robotics-ai-research/" target="_blank">THE ROBOT REPORT</a>, <a href="https://siliconangle.com/2019/06/20/facebook-debuts-pyrobot-open-source-framework-controlling-robots/"
                                    target="_blank">SiliconANGLE</a>, <a href="https://www.ibtimes.com/pyrobot-facebooks-open-source-robotics-framework-designed-make-controlling-bots-easy-2802365" target="_blank">IB Times</a>, <a href="https://sdtimes.com/ai/ai-robotics-research-platform-pyrobot-now-open-sourced/"
                                    target="_blank">SD Times</a>, <a href="https://towardsdatascience.com/introducing-pyrobot-how-facebook-is-democratizing-robotics-programming-using-deep-learning-7ed3c2a4b065" target="_blank">Medium</a>
                                <p></p>
                            </p>
                            <p>An easy-to-use python interface for robot learning and a low-cost robot learning platform.</p>
                        </td>
                    </tr>


                    <tr>
                        <td width="25%" align="center">
                            <!-- <img src="images/chen2018learning.jpg" width="100%"> -->
                            <!-- <br> -->
                            <img src="https://thumbs.gfycat.com/ScarceChiefAsianconstablebutterfly-size_restricted.gif" width="100%">
                        </td>
                        <td valign="top" width="75%">
                            <p>
                                <papertitle>Learning Exploration Policies for Navigation</papertitle>
                                <br>
                                <strong>Tao Chen</strong>,
                                <a href="http://saurabhg.web.illinois.edu/" target="_blank">Saurabh Gupta</a>,
                                <a href="http://www.cs.cmu.edu/~abhinavg/" target="_blank">Abhinav Gupta</a>
                                <br>
                                <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2019
                                <br>
                                <a href="https://arxiv.org/abs/1903.01959" target="_blank">paper</a> / <a href="javascript:toggleblock('chen2018learning_bib')">bibtex</a> / <a href="https://sites.google.com/view/exploration-for-nav/home" target="_blank">project page</a>                                / <a href="https://youtu.be/qenGbObEkOI" target="_blank">video</a> / <a href="https://github.com/taochenshh/exp4nav" target="_blank">code</a> / <a href="files/exp_poster.pdf" target="_blank">poster</a>
                                <bibtext xml:space="preserve" id="chen2018learning_bib">
                                    @inproceedings{chen2018learning,<br /> author = "Chen, Tao and Gupta, Saurabh and Gupta, Abhinav",<br /> title = "Learning Exploration Policies for Navigation",<br /> booktitle = "International Conference on Learning
                                    Representations",
                                    <br /> year = "2019",<br /> url = "https://openreview.net/forum?id=SyMWn05F7"<br /> }
                                    <br />
                                </bibtext>
                                <script language="JavaScript">
                                    hideblock('chen2018learning_bib');
                                </script>
                                <p></p>
                            </p>
                            <p> A framework for learning to explore novel environments with on-board sensors in the testing time.</p>
                        </td>
                    </tr>

                    <tr>
                        <td width="25%">
                            <img src='images/hcp_logo.png' width="100%">
                            <br>
                            <img src="https://thumbs.gfycat.com/SafeNeighboringHydatidtapeworm-size_restricted.gif" width="100%">
                        </td>
                        <td valign="top" width="75%">
                            <p>
                                <papertitle>Hardware Conditioned Policies for Multi-Robot Transfer Learning</papertitle>
                                <br>
                                <strong>Tao Chen</strong>,
                                <a href="http://adithyamurali.com/" target="_blank">Adithya Murali</a>,
                                <a href="http://www.cs.cmu.edu/~abhinavg/" target="_blank">Abhinav Gupta</a>
                                <br>
                                <em>Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2018
                                <br>
                                <a href="https://arxiv.org/abs/1811.09864" target="_blank">paper</a> / <a href="javascript:toggleblock('chen2018hardware_bib')">bibtex</a> / <a href="https://sites.google.com/view/robot-transfer-hcp/home" target="_blank">project page</a>                                / <a href="https://youtu.be/8odcwNOtAwI" target="_blank">video</a> / <a href="https://github.com/taochenshh/hcp" target="_blank">code</a> / <a href="files/hcp_poster.pdf" target="_blank">poster</a>
                                <bibtext xml:space="preserve" id="chen2018hardware_bib">
                                    @inproceedings{chen2018hardware,<br /> title={Hardware Conditioned Policies for Multi-Robot Transfer Learning},<br /> author={Chen, Tao and Murali, Adithyavairavan and Gupta, Abhinav},<br /> booktitle={Advances in Neural
                                    Information Processing Systems},<br /> pages={9355--9366},
                                    <br /> year={2018}
                                    <br /> }
                                    <br />
                                </bibtext>
                                <script language="JavaScript">
                                    hideblock('chen2018hardware_bib');
                                </script>
                                <p></p>
                            </p>
                            <p> One policy to control many robots that are kinematically and dynamically different.</p>
                        </td>
                    </tr>

                    <tr>
                        <td width="25%">
                            <img src='https://thumbs.gfycat.com/TepidAnyBoubou-size_restricted.gif' width="100%">
                            <br>
                            <p></p>
                            <img src="https://thumbs.gfycat.com/BlondHopefulHarpseal-size_restricted.gif" width="100%">
                        </td>
                        <td valign="top" width="75%">
                            <p>
                                <papertitle>Development of a Soft Elastomeric Gripper for Dexterous Grasping</papertitle>
                                <br>
                                <strong>Tao Chen</strong>,
                                <a href="http://me.sjtu.edu.cn/teacher_directory1/guguoying.html" target="_blank">Guo-Ying Gu</a>
                                <br>
                                <em>Bachelor's Thesis</em>, 2016
                                <br> Awarded <strong>2016 Excellent Bachelor Thesis (Top 1%)</strong> of Shanghai Jiao Tong University
                                <br>
                                <a href="https://sites.google.com/view/soft-gripper/home" target="_blank">project page</a>
                                <p></p>
                            </p>
                            <p align="justify">
                                A four-fingered soft gripper with multi-cavity pneumatic elastomer actuators (MCPEA) for grasping objects with different sizes, shapes, fragility.
                            </p>
                        </td>
                    </tr>

                </table>


                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td>
                            <heading>Work Experience</heading>
                        </td>
                    </tr>
                </table>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td width="25%">
                            <img src='images/automap_logo.png' width="100%">
                            <br>
                            <img src="https://thumbs.gfycat.com/SimplisticImpassionedGermanspitz-size_restricted.gif" width="100%">
                        </td>
                        <td valign="top" width="75%">
                            <p>
                                <papertitle>Autonomous Exploration for Dense Map Construction</papertitle>
                                <br>
                                <strong>Tao Chen</strong>
                                <br>
                                <em>Shanghai LX Robotics</em>, 2017
                                <p></p>
                            </p>
                            <p align="justify">A key step for robots to get popularized into our daily life is that robots should be able to automatically explore the new environment when they are deployed in new houses or buildings. In this project, I combine the strength
                                of motion planning (OMPL and SBPL), frontier-based exploration, SLAM (ORB-SLAM2), and object recognition and segmentation (FCIS) techniques to build an automatic mapping system that can autonomously explore the new houses,
                                recognize daily objects and remember their locations while keep building the dense map as it moves. After the map is built, the robot can be asked to find and move to the objects it has seen (like cup, monitor) autonomously.</p>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td>
                            <heading>Teaching</heading>
                        </td>
                    </tr>
                </table>


                <table width="100%" align="center" border="0" cellpadding="20">
                    <tr>
                        <td width="25%" align="center">
                            <img src="images/teach_logo.png" width="80%">
                        </td>
                        <td width="75%" valign="top">
                            <p>
                                <a href="https://pulkitag.github.io/6.884/" target="_blank">
                                    <papertitle>MIT 6.884 Computational Sensorimotor Learning - Spring 2021</papertitle>
                                </a>
                                <br> Teaching Assistant (TA)
                                <br>
                            </p>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellpadding="20">
                    <tr>
                        <td width="25%" align="center">
                            <img src="images/teach_logo.png" width="80%">
                        </td>
                        <td width="75%" valign="top">
                            <p>
                                <a href="https://pulkitag.github.io/rlbootcamp-iap/" target="_blank">
                                    <papertitle>MIT 6.S090 Deep Learning for Control - IAP 2021</papertitle>
                                </a>
                                <br> Instructor
                                <br>
                            </p>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellpadding="20">
                    <tr>
                        <td width="25%" align="center">
                            <img src="images/teach_logo.png" width="80%">
                        </td>
                        <td width="75%" valign="top">
                            <p>
                                <a href="https://sites.google.com/andrew.cmu.edu/16824-spring2019/" target="_blank">
                                    <papertitle>CMU 16-824 Visual Learning and Recognition - Spring 2019</papertitle>
                                </a>
                                <br> Teaching Assistant (TA)
                                <br>
                            </p>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td>
                            <heading>Course Projects</heading>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellpadding="20">
                    <tr>
                        <td width="25%" align="center">
                            <img src="https://thumbs.gfycat.com/ClearcutLegitimateIndianringneckparakeet-size_restricted.gif" width="100%">
                        </td>
                        <td width="75%" valign="top">
                            <p>
                                <a href="https://youtu.be/sxvL3HohEog" target="_blank">
                                    <papertitle>Robot Construction via Planning and Learning</papertitle>
                                </a>
                                <br>
                                <strong>Tao Chen</strong>, Xianyi Cheng
                                <br>
                                <em>Learning for Manipulation</em>, 2018
                                <br> Instructor: <a href="https://www.ri.cmu.edu/ri-faculty/oliver-kroemer/" target="_blank">Oliver Kroemer</a>
                                <br>
                                <a href="https://youtu.be/sxvL3HohEog" target="_blank">video1</a> / <a href="https://youtu.be/K-2i6M3E-7g" target="_blank">video2</a> / <a href="https://youtu.be/cNDd-CNf0g0" target="_blank">video3</a> / <a href="https://github.com/taochenshh/block_stacking"
                                    target="_blank">code</a> / <a href="https://drive.google.com/open?id=1HNmbnL3vTYEzdehcZsN8x6dRKCBJ9_be" target="_blank">report</a>
                                <p></p>
                                <p align="justify">
                                    We combined the symbolic planning and supervised learning to efficiently learn to move a set of blocks from an initial configuration to a goal configuration (a.k.a, robot construction problem). The symbolic planning module plans the sequence actions (path)
                                    to move the blocks (a block or a sub-assembly) to reach the goal configurations. The supervised learning module (stability checker) predicts whether the state (RGB image) is stable or not so that the planning module
                                    only plans with the actions that lead to stable states. We used domain randomization techniques to generate more diversified visual data to make the stability checker more robust. These two modules combined lead to
                                    an effective way to solve the robot construction problem.
                                </p>
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td width="25%">
                            <img src="https://thumbs.gfycat.com/LonePortlyAnhinga-size_restricted.gif" width="100%">
                        </td>
                        <td width="75%" valign="top">
                            <p>
                                <a href="https://youtu.be/p-u4_u9Ocdc" target="_blank">
                                    <papertitle>Design and Manufacturing of a Tennis Ball Collecting Robot</papertitle>
                                </a>
                                <br>
                                <strong>Tao Chen</strong>, Matthew Stouder, Zhedong Han, Duankang Fu, Sara Lyons, Zhishang Xu
                                <br>
                                <em>GEARE program, Purdue University</em>, 2015
                                <br>
                                <a href="https://youtu.be/p-u4_u9Ocdc" target="_blank">video</a> / <a href="https://bitbucket.org/taochenshh/differential_drive_control/src/master/" target="_blank">code</a>
                                <p></p>
                                <p align="justify">
                                    This project was the Senior Engineering Design Capstone project at Purdue University. We built an aesthetically pleasing tennis ball collecting robot which can collect tennis balls dispersed on a tennis court. I was fully responsible for all the programming
                                    and control tasks for the robot.
                                </p>
                            </p>
                        </td>
                    </tr>



                    <tr>
                        <td width="25%">
                            <img src="https://thumbs.gfycat.com/WellmadeHonorableFairyfly-size_restricted.gif" width="100%">
                        </td>
                        <td width="75%" valign="top">
                            <p>
                                <a href="https://youtu.be/DPbkB0Hufag" target="_blank">
                                    <papertitle>2015 RoboMaster Robotics Competition</papertitle>
                                </a>
                                <br>
                                <strong>Tao Chen</strong>, Mechanical Team Leader
                                <br>
                                <em>hosted by <a href="https://www.dji.com/" target="_blank">DJI</a> </em>, 2015
                                <br>
                                <a href="https://youtu.be/DPbkB0Hufag" target="_blank">video</a>
                                <p></p>
                                <p align="justify">
                                    This competition was a real-life version of Counter-Strike game with real mobile robots. I led and managed the mechanical group. We won the second prize in 2015 National RoboMaster Robotics Competition of east China and the third prize in 2015 National
                                    RoboMaster Robotics Competition Final.
                                </p>
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td width="25%">
                            <img src="images/rehab_logo.jpg" width="100%">
                        </td>
                        <td width="75%" valign="top">
                            <p>
                                <a href="https://sites.google.com/view/active-rehab/home" target="_blank">
                                    <papertitle>An Active Rehabilitation Device for Elbow Joints</papertitle>
                                </a>
                                <br>
                                <strong>Tao Chen</strong>, Leader
                                <br> Advisor: Prof. Hua Shao
                                <br>
                                <em>Engineering Design</em>, 2015
                                <br>
                                <strong>China Patent, CN105148460B</strong>
                                <br>
                                <a href="https://sites.google.com/view/active-rehab/home" target="_blank">project page</a>
                                <p></p>
                                <p align="justify">
                                    We designed and built an inexpensive yet effective elbow joint rehabilitation device. The device is only composed of mechanical parts such as a lead screw, and a four-bar mechanism. It can help patients exercise their elbow joints in an inexpensive way,
                                    and it is also very easy to use and portable. We have applied a patent (Application Number: CN201510472161.5, <strong>Publication Number: CN105148460B</strong>) for this rehabilitation
                                    device.
                                </p>
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td width="25%">
                            <img src="images/track1.png" width="49%">
                            <img src="images/track2.png" width="49%">
                        </td>
                        <td width="75%" valign="top">
                            <p>
                                <papertitle>A High-adaptability Rescue Robot</papertitle>
                                <br>
                                <strong>Tao Chen</strong>, Leader
                                <br> Advisor: Prof. Qinghua Liang
                                <br>
                                <em>Design and Manufacturing</em>, 2014
                                <br>
                                <a href="https://github.com/taochenshh/Robot-Control-via-Bluetooth" target="_blank">code 1</a> / <a href="https://github.com/taochenshh/Robot-Car-Control-with-ATmega2560" target="_blank">code 2</a>
                                <p></p>
                                <p align="justify">
                                    We built a high-adaptability track robot with two separate frames. I led and managed the team and I was responsible for electronic control, programming, and part of manufacturing.
                                </p>
                            </p>
                        </td>
                    </tr>

                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td>
                            <heading>Service</heading>
                        </td>
                    </tr>

                    <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                            Reviewer for
                            <a href="https://iclr.cc/" target="_blank">ICLR (Outstanding Reviewer)</a>,
                            <a href="https://nips.cc/" target="_blank">NeurIPS</a>,
                            <a href="https://icml.cc/" target="_blank">ICML</a>,
                            <a href="https://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra" target="_blank">ICRA</a>,
                            <a href="https://softroboticsconference.org/" target="_blank">RoboSoft</a>,
                            <a href="https://www.ieee-ras.org/conferences-workshops/fully-sponsored/humanoids" target="_blank">Humanoids</a>,
                            <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI</a>,
                            <a href="http://www.ieee-ies.org/pubs/transactions-on-industrial-informatics" target="_blank">TII</a>, etc.
                        </td>
                    </tr>
                </table>



                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                        <tr>
                            <td>
                                <br>
                                <p align="right">
                                    <font size="2">
                                        <a href="https://people.eecs.berkeley.edu/~barron/" target="_blank">This guy makes a nice webpage.</a>
                                    </font>
                                </p>
                            </td>
                        </tr>
                    </tbody>
                </table>
                <!-- Global site tag (gtag.js) - Google Analytics -->
                <script async src="https://www.googletagmanager.com/gtag/js?id=UA-79592980-2"></script>
                <script>
                    window.dataLayer = window.dataLayer || [];

                    function gtag() {
                        dataLayer.push(arguments);
                    }
                    gtag('js', new Date());

                    gtag('config', 'UA-79592980-2');
                </script>

            </td>
        </tr>
    </table>
</body>

</html>